{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "נבצע includes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import re\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "search_terms = {\"arizona\": \"arizona\",    \"nature\": \"nature\",\n",
    "    \"purple\": \"purple\",\n",
    "    \"art\": \"art\",\n",
    "    \"bridge\": \"bridge\",\n",
    "    \"shop\": \"shop\",\n",
    "    \"farm\": \"farm\",\n",
    "    \"bar\": \"bar\",\n",
    "    \"day\": \"day\",\n",
    "    \"house\": \"house\",\n",
    "    \"orange\": \"orange\",\n",
    "    \"flowers\": \"flowers\",\n",
    "    \"car\": \"car\",\n",
    "    \"dog\": \"dog\",\n",
    "    \"garden\": \"garden\",\n",
    "    \"music\": \"music\",\n",
    "    \"sky\": \"sky\",\n",
    "    \"snow\": \"snow\",\n",
    "    \"river\": \"river\",\n",
    "    \"sun\": \"sun\",\n",
    "    \"sunset\": \"sunset\",\n",
    "    \"beach\": \"beach\",\n",
    "    \"cat\": \"cat\"}\n",
    "driver_path = r\"C:\\Users\\barex\\Downloads\\chromedriver_win32 (1)\\chromedriver.exe\"\n",
    "options = Options()\n",
    "options.add_argument('--mute-audio')\n",
    "options.add_argument('--headless')\n",
    "capabilities = DesiredCapabilities.CHROME.copy()\n",
    "capabilities['acceptInsecureCerts'] = True\n",
    "driver = webdriver.Chrome(executable_path=driver_path, options=options, desired_capabilities=capabilities)\n",
    "all_urls = {}\n",
    "\n",
    "for search_term, tag in search_terms.items():\n",
    "    urls = []\n",
    "    url = f\"https://www.flickr.com/photos/tags/{search_term}\"\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    SCROLL_PAUSE_TIME = 8\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    count = 0\n",
    "    while True:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(SCROLL_PAUSE_TIME)\n",
    "        try:\n",
    "            load_more = driver.find_element_by_xpath(\"//button[@class='load-more-suggestions loaded-suggestions-show']\")\n",
    "            load_more.click()\n",
    "            time.sleep(SCROLL_PAUSE_TIME)\n",
    "        except:\n",
    "            break\n",
    "        if driver.find_elements_by_xpath(\"//a[@class='page-arrow right']\") == []:\n",
    "            break\n",
    "        count += 1\n",
    "        if count >= 10000:\n",
    "            break\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "    html = driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    links = []\n",
    "    for a in soup.select('div.view.tag-photos-everyone-view a.overlay'):\n",
    "        link = a.get('href')\n",
    "        links.append(f'https://www.flickr.com{link}')\n",
    "    all_urls[search_term] = links\n",
    "\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((all_urls[day]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n"
     ]
    }
   ],
   "source": [
    "print(len(all_urls[\"arizona\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000 URLs found for arizona\n",
      "4000 URLs found for nature\n",
      "4000 URLs found for purple\n",
      "4000 URLs found for art\n",
      "3999 URLs found for bridge\n",
      "3996 URLs found for shop\n",
      "3999 URLs found for farm\n",
      "3996 URLs found for bar\n",
      "3999 URLs found for day\n",
      "3999 URLs found for house\n",
      "4000 URLs found for orange\n",
      "3999 URLs found for flowers\n",
      "3985 URLs found for car\n",
      "3998 URLs found for dog\n",
      "3993 URLs found for garden\n",
      "3997 URLs found for music\n",
      "3999 URLs found for sky\n",
      "3997 URLs found for snow\n",
      "3999 URLs found for river\n",
      "4000 URLs found for sun\n",
      "3998 URLs found for sunset\n",
      "3998 URLs found for beach\n",
      "3999 URLs found for cat\n",
      "Data saved to flickr_urls.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.options import Options as FirefoxOptions\n",
    "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "# הקובץ שבו נרצה לשמור את התוצאות\n",
    "filename = 'flickr_urls.csv'\n",
    "driver_path = r'C:\\Users\\barex\\Downloads\\geckodriver-v0.33.0-win32\\geckodriver.exe'\n",
    "firefox_binary = 'C:\\\\Program Files\\\\Mozilla Firefox\\\\firefox.exe'\n",
    "\n",
    "firefox_options = FirefoxOptions()\n",
    "firefox_options.binary_location = firefox_binary\n",
    "firefox_options.add_argument('--mute-audio')\n",
    "firefox_options.add_argument('--headless')\n",
    "\n",
    "capabilities = DesiredCapabilities.FIREFOX.copy()\n",
    "capabilities['acceptInsecureCerts'] = True\n",
    "\n",
    "search_terms = {\"arizona\": \"arizona\", \"nature\": \"nature\", \"purple\": \"purple\",\n",
    "                \"art\": \"art\", \"bridge\": \"bridge\", \"shop\": \"shop\",\n",
    "                \"farm\": \"farm\", \"bar\": \"bar\", \"day\": \"day\", \"house\": \"house\",\n",
    "                \"orange\": \"orange\", \"flowers\": \"flowers\", \"car\": \"car\",\n",
    "                \"dog\": \"dog\", \"garden\": \"garden\", \"music\": \"music\",\n",
    "                \"sky\": \"sky\", \"snow\": \"snow\", \"river\": \"river\", \"sun\": \"sun\",\n",
    "                \"sunset\": \"sunset\", \"beach\": \"beach\", \"cat\": \"cat\"}\n",
    "\n",
    "with webdriver.Firefox(executable_path=driver_path, options=firefox_options, desired_capabilities=capabilities) as driver:\n",
    "    all_urls = {}\n",
    "\n",
    "    for search_term, tag in search_terms.items():\n",
    "        urls = []\n",
    "        for i in range(1, 81):\n",
    "            url = f\"https://www.flickr.com/photos/tags/{search_term}/page{i}\"\n",
    "            driver.get(url)\n",
    "            time.sleep(2)\n",
    "            if driver.current_url != url:\n",
    "                break\n",
    "            SCROLL_PAUSE_TIME = 1\n",
    "            last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            count = 0\n",
    "            while True:\n",
    "                driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                time.sleep(SCROLL_PAUSE_TIME)\n",
    "                try:\n",
    "                    load_more = driver.find_element_by_xpath(\"//button[@class='load-more-suggestions loaded-suggestions-show']\")\n",
    "                    load_more.click()\n",
    "                    time.sleep(SCROLL_PAUSE_TIME)\n",
    "                except:\n",
    "                    break\n",
    "                if driver.find_elements_by_xpath(\"//a[@class='page-arrow right']\") == []:\n",
    "                    break\n",
    "                count += 1\n",
    "                if count >= 10000:\n",
    "                    break\n",
    "                new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "                if new_height == last_height:\n",
    "                    break\n",
    "                last_height = new_height\n",
    "            html = driver.page_source\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            links = []\n",
    "            for a in soup.select('div.view.tag-photos-everyone-view a.overlay'):\n",
    "                link = a.get('href')\n",
    "                links.append(f'https://www.flickr.com{link}')\n",
    "            all_urls.setdefault(search_term, []).extend(links)\n",
    "            if len(links) == 0:\n",
    "                break\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "for tag, urls in all_urls.items():\n",
    "    print(f\"{len(urls)} URLs found for {tag}\")\n",
    "\n",
    "with open(filename, mode='w', newline='') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow(['Search term', 'Image URL'])\n",
    "\n",
    "    for tag, urls in all_urls.items():\n",
    "        for url in urls:\n",
    "            writer.writerow([tag, url])\n",
    "\n",
    "print(f\"Data saved to {filename}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "General_information ={\n",
    "    \"tag\": \"Tag\",\n",
    "    \"url\": \"URL\",\n",
    "    \"views\": \"Views\",\n",
    "    \"likes\": \"Likes\",\n",
    "    \"comments\": \"Comments\",\n",
    "    \"date\": \"Date\",\n",
    "    \"location\": \"Location\",\n",
    "    \"pro\": \"Pro\",\n",
    "    \"photographer\": \"Photographer\"\n",
    "}\n",
    "\n",
    "\n",
    "more_info={\n",
    "    \"Format\": \"Format\",\n",
    "    \"Contrast\": \"Contrast\",\n",
    "    \"Saturation\": \"Saturation\",\n",
    "    \"Sharpness\": \"Sharpness\",\n",
    "    \"Image width\": \"Image Width\",\n",
    "    \"Image height\": \"Image Height\",\n",
    "    \"Camera type\": \"Camera Type\"\n",
    "}\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ייבוא כל URLS לשמתנה"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "file_path = r\"C:\\Users\\barex\\OneDrive - Holon Institute of Technology\\לימודים\\שנה ב\\סמסטר 2\\מדעי הנתונים\\פרוייקט תמונות בר ומתן\\flickr_urls.csv\"\n",
    "\n",
    "urls = []\n",
    "tags = []\n",
    "\n",
    "with open(file_path, newline='') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for row in reader:\n",
    "        tag = row[0]\n",
    "        url = row[1]\n",
    "        tags.append(tag)\n",
    "        urls.append(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_url = urls[0]\n",
    "urls = urls[1:]\n",
    "first_tags =tags[0]\n",
    "tags = tags[1:]\n",
    "\n",
    "first_url = urls[0]\n",
    "urls = urls[1:]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "העברת המידע לפי מילונים "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "General_information ={\n",
    "    \"tag\": \"Tag\",\n",
    "    \"url\": \"URL\",\n",
    "    \"views\": \"Views\",\n",
    "    \"likes\": \"Likes\",\n",
    "    \"comments\": \"Comments\",\n",
    "    \"date\": \"Date\",\n",
    "    \"pro\": \"Pro\",\n",
    "    \"photographer\": \"Photographer\"\n",
    "}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def scrape_links_General_information(urls, tags):\n",
    "    class_to_key = {\n",
    "        'fave-count-label': 'likes',\n",
    "        'comment-count-label': 'comments',\n",
    "        'date-taken-label': 'date',\n",
    "        'icon-pro-badge': 'pro',\n",
    "        'owner-name': 'photographer'\n",
    "    }\n",
    "    new_urls = set()\n",
    "    for url in urls:\n",
    "        if '%20' in url:\n",
    "            new_url = url.replace('%20', ' ')\n",
    "            new_urls.add(new_url)\n",
    "        else:\n",
    "            new_urls.add(url)\n",
    "    scraped_data = []\n",
    "    for url, tag in zip(new_urls, tags):\n",
    "        # Check if the URL starts with \"http://\" or \"https://\"\n",
    "        if not url.startswith((\"http://\", \"https://\")):\n",
    "            url = \"http://\" + url\n",
    "        info_dict = {'url': url, 'tag': tag}\n",
    "\n",
    "        soup = BeautifulSoup(requests.get(url).content, 'html.parser')\n",
    "        for class_name, key in class_to_key.items():\n",
    "            value = soup.find(class_=class_name)\n",
    "            if value is not None:\n",
    "                if key == 'pro':\n",
    "                    value = '1'\n",
    "                elif key == 'photographer':\n",
    "                    value = value.text.strip()\n",
    "                elif key == 'date':\n",
    "                    value = value.text.replace('Taken on ', '').strip()\n",
    "                else:\n",
    "                    value = value.text.strip()\n",
    "            else:\n",
    "                value = 'NaN'\n",
    "            info_dict[key] = value\n",
    "\n",
    "        scraped_data.append(info_dict)\n",
    "        \n",
    "    return scraped_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def write_to_csv(data):\n",
    "    with open('General_information.csv', mode='w', encoding='utf-8', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        # Write header row\n",
    "        writer.writerow(['url', 'tag', 'likes', 'comments', 'date', 'pro', 'photographer'])\n",
    "        # Write data rows\n",
    "        for item in data:\n",
    "            writer.writerow([item.get('url', ''),\n",
    "                             item.get('tag', ''),\n",
    "                             item.get('likes', ''),\n",
    "                             item.get('comments', ''),\n",
    "                             item.get('date', ''),\n",
    "                             item.get('pro', ''),\n",
    "                             item.get('photographer', '')])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_test = [\n",
    "        'https://www.flickr.com/photos/139103596@N02/52287265176/',\n",
    "        'https://www.flickr.com/photos/144721100@N04/49307165796/']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_data_General_information=scrape_links_General_information(url_test, tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_to_csv(scraped_data_General_information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://www.flickr.com/photos/144721100@N04/49307165796/',\n",
       "  'tag': 'arizona',\n",
       "  'likes': '126',\n",
       "  'comments': '70',\n",
       "  'date': 'December 21, 2019',\n",
       "  'pro': '1',\n",
       "  'photographer': 'Irina Muraviyova'},\n",
       " {'url': 'https://www.flickr.com/photos/139103596@N02/52287265176/',\n",
       "  'tag': 'arizona',\n",
       "  'likes': '141',\n",
       "  'comments': '80',\n",
       "  'date': 'June 6, 2022',\n",
       "  'pro': '1',\n",
       "  'photographer': 'James Pillion'}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scraped_data_General_information"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
